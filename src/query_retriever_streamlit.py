import os
import streamlit as st
import numpy as np
import faiss
import pandas as pd
from rank_bm25 import BM25Okapi
from dotenv import load_dotenv

# LangChain / Custom modules
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS

# -----------------------------------------------------------------------------
# 1) ì„¤ì • ìƒìˆ˜
# -----------------------------------------------------------------------------
ALPHA = 0   # BM25ì™€ FAISS ë¹„ì¤‘ (0 => FAISS 100%, 1 => BM25 100%)
RAG_TOP_K = 5      # ìµœì¢…ì ìœ¼ë¡œ LLM(RAG)ì— ì „ë‹¬í•  ë¬¸ì„œ ê°œìˆ˜
BM25_TOP_K = RAG_TOP_K // 2     # BM25 ê²€ìƒ‰ì—ì„œ ìƒìœ„ ëª‡ ê°œë¥¼ ì„ íƒí• ì§€
FAISS_TOP_K = 10    # FAISS(MMR)ì—ì„œ ìƒìœ„ ëª‡ ê°œë¥¼ ì„ íƒí• ì§€
FINAL_VIEWABLE_DOCUMENT_SCORE = 0.5 # ë³´ì—¬ì§€ëŠ” ë¬¸ì„œì˜ ê¸°ì¤€ì ìˆ˜

# -----------------------------------------------------------------------------
# 2) .env ë¡œë“œ & OpenAI API
# -----------------------------------------------------------------------------
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise ValueError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
os.environ["OPENAI_API_KEY"] = api_key

# -----------------------------------------------------------------------------
# 3) Prompt íŒŒì¼ ë¡œë“œ
# -----------------------------------------------------------------------------
prompt_file_path = "src/prompt/prompt.txt"
def load_prompt_from_file(file_path: str) -> str:
    with open(file_path, "r", encoding="utf-8") as f:
        return f.read()

prompt_text = load_prompt_from_file(prompt_file_path)

# -----------------------------------------------------------------------------
# 4) FAISS ë¡œë“œ (METRIC_INNER_PRODUCT ê°•ì œ)
# -----------------------------------------------------------------------------
embedding_model = OpenAIEmbeddings(model="text-embedding-3-small")

vectorstore = FAISS.load_local(
    "vdb/faiss_index",
    embeddings=embedding_model,
    allow_dangerous_deserialization=True
)
vectorstore.index.metric_type = faiss.METRIC_INNER_PRODUCT

# -----------------------------------------------------------------------------
# 5) BM25 ì¸ë±ìŠ¤ (ì—‘ì…€: "ì œëª© + ë³¸ë¬¸_ì›ë³¸")
# -----------------------------------------------------------------------------
excel_file = "data_source/ì„¸ë¬´ì‚¬ ë°ì´í„°ì „ì²˜ë¦¬_20250116.xlsx"
df = pd.read_excel(excel_file)

bm25_documents = df.apply(lambda row: f"{row['ì œëª©']} {row['ë³¸ë¬¸_ì›ë³¸']}", axis=1).tolist()
bm25_tokenized_docs = [doc.split() for doc in bm25_documents]
bm25 = BM25Okapi(bm25_tokenized_docs)

# -----------------------------------------------------------------------------
# ì •ê·œí™”ë¥¼ ìœ„í•œ í•¨ìˆ˜ (Min-Max)
# -----------------------------------------------------------------------------
def min_max_normalize(value, min_v, max_v):
    if max_v == min_v:
        return 0.0
    return (value - min_v) / (max_v - min_v)

# -----------------------------------------------------------------------------
# 6) í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í•¨ìˆ˜
#    BM25_TOP_K + FAISS_TOP_K => ì ìˆ˜ í•©ì‚° => ìƒìœ„ RAG_TOP_K ë¬¸ì„œ ë°˜í™˜
#    ì—¬ê¸°ì„œ, BM25 ì ìˆ˜ë¥¼ 0~1 ë²”ìœ„ë¡œ ì •ê·œí™”
# -----------------------------------------------------------------------------
def hybrid_search(query: str):
    """
    Returns a list of (doc_text, final_score) sorted by descending score.
    """
    print(f" - ì…ë ¥: {query}")
    # 1) ì „ì²´ ë¬¸ì„œ BM25 ì ìˆ˜ êµ¬í•˜ê¸°
    tokenized_query = query.split()
    bm25_scores = bm25.get_scores(tokenized_query)  # ëª¨ë“  ë¬¸ì„œ BM25 ì ìˆ˜
    doc_bm25_map = dict(zip(bm25_documents, bm25_scores))
    
    # 2) BM25 ì ìˆ˜ Min-Max ì •ê·œí™” (0~1)
    min_b = min(doc_bm25_map.values())
    max_b = max(doc_bm25_map.values()) if doc_bm25_map else 0.0
    
    normalized_bm25_map = {
        doc: min_max_normalize(score, min_b, max_b)
        for doc, score in doc_bm25_map.items()
    }

    # 3) ê·¸ì¤‘ ìƒìœ„ k => [(ë¬¸ì„œí…ìŠ¤íŠ¸, ì •ê·œí™”ëœBM25ì ìˆ˜), ...]
    bm25_top = sorted(
        normalized_bm25_map.items(),
        key=lambda x: x[1],
        reverse=True
    )[:BM25_TOP_K]

    # 4) FAISS (MMR) ê²€ìƒ‰ (with score)
    # faiss_results_with_scores = vectorstore.similarity_search_with_score(
    #     query,
    #     search_type="mmr",
    #     search_kwargs={
    #         "k": FAISS_TOP_K,
    #         "fetch_k": 10,
    #         "lambda_mult": 0.9
    #     }
    # )
    faiss_results_with_scores = vectorstore.similarity_search_with_score(
        query,
        k=FAISS_TOP_K
    )

    # 5) í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ í•©ì‚°
    doc_score_map = {}

    # (A) ë¨¼ì € BM25 ìƒìœ„ kê°œ ë¬¸ì„œë¥¼ doc_score_map ì— ë°˜ì˜
    for doc_text, bm25_val in bm25_top:
        doc_score_map[doc_text] = bm25_val
        print(f"[BM25] normalized={bm25_val:.3f} | doc_text={doc_text[:20]}...")

    # (B) FAISS ê²°ê³¼ (distance=ë‚®ì„ìˆ˜ë¡ ìœ ì‚¬) => similarity=1 - distance
    faiss_results_with_scores_sorted = sorted(
        faiss_results_with_scores, key=lambda x: 1.0 - x[1], reverse=True
    )
    
    for doc_obj, distance_value in faiss_results_with_scores_sorted:
        doc_text = doc_obj.page_content
        similarity = 1.0 - distance_value
        similarity = max(0.0, similarity)  # ìŒìˆ˜ ë³´ì •
        if similarity < 0.0:
            similarity = 0.0
        
        bm25_s = doc_score_map.get(doc_text, 0.0)  # ë§Œì•½ BM25 ìƒìœ„ kì— ì—†ìœ¼ë©´ 0
        final_score = ALPHA * bm25_s + (1 - ALPHA) * similarity
        doc_score_map[doc_text] = final_score

        print(f"[FAISS] bm25_s={bm25_s:.3f} | sim={similarity:.3f} => final={final_score:.3f} | doc_text={doc_text[:20]}...")

    # 6) ìƒìœ„ K ë½‘ì•„ì„œ ë°˜í™˜
    sorted_docs = sorted(doc_score_map.items(), key=lambda x: x[1], reverse=True)[:RAG_TOP_K]
    return sorted_docs

# -----------------------------------------------------------------------------
# 7) RAG(LLM QA) êµ¬ì„±
# -----------------------------------------------------------------------------
prompt = PromptTemplate(
    input_variables=["question", "context"],
    template=prompt_text
)
llm = ChatOpenAI(model_name="gpt-4o", temperature=0)
parser = StrOutputParser()

def generate_answer(question: str):
    hybrid_results = hybrid_search(question)
    if not hybrid_results:
        return "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.", []

    # context ìƒì„±
    context_list = []
    for idx, (doc_text, score) in enumerate(hybrid_results, 1):
        snippet = f"[ë¬¸ì„œ {idx} | ìŠ¤ì½”ì–´={score:.3f}]\n{doc_text}\n"
        context_list.append(snippet)

    context_text = "\n\n".join(context_list)

    prompt_input = {"question": question, "context": context_text}
    result = llm.invoke(prompt.format(**prompt_input))
    answer = result.content

    return answer, hybrid_results

# -----------------------------------------------------------------------------
# 8) Streamlit ì•±
# -----------------------------------------------------------------------------
st.set_page_config(page_title="ì„¸ë¬´ì‚¬ ì±—ë´‡ (í•˜ì´ë¸Œë¦¬ë“œ)", page_icon="ğŸ¤–", layout="wide")
st.title("ğŸ“„ ì„¸ë¬´ì‚¬ ì±—ë´‡ (BM25 + FAISS(MMR) í•˜ì´ë¸Œë¦¬ë“œ, BM25=0~1 ì •ê·œí™”)")

st.write("""
**í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìˆœì„œ**  
1) **BM25** ì „ ë¬¸ì„œ ì ìˆ˜ -> **Min-Max ì •ê·œí™”(0~1)** -> ìƒìœ„ k  
2) **FAISS(MMR)** top-k (with score)  
3) ë‘ ì ìˆ˜ ê°€ì¤‘í•©(`ALPHA`)  
4) ìµœì¢… ìƒìœ„ kê°œë¥¼ LLMì— ì „ë‹¬(RAG)  
""")

with st.form("chat_form"):
    question = st.text_input(
        "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:",
        placeholder="ì˜ˆ: ëŒ€í•™ì›ìƒì¸ ë°°ìš°ìê°€ 2024ë…„ 6ì›”ì— ì—°êµ¬ìš©ì—­ë¹„ 500ë§Œì›ì„ ë°›ì€ ê²½ìš° ë°°ìš°ìê³µì œê°€ ê°€ëŠ¥í•´?"
    )
    submit_button = st.form_submit_button(label="ì§ˆë¬¸í•˜ê¸°")

if submit_button and question.strip():
    with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
        answer, top_docs = generate_answer(question)

    st.subheader("ğŸ’¡ ìƒì„±ëœ ë‹µë³€")
    st.write(answer)

    st.subheader("ğŸ” ì°¸ì¡°í•œ ë¬¸ì„œ")
    for idx, (doc_text, score) in enumerate(top_docs, start=1):
        if score >= FINAL_VIEWABLE_DOCUMENT_SCORE:  # âœ… ì ìˆ˜ ê¸°ì¤€ í•„í„°ë§
            if "ë³¸ë¬¸:" in doc_text:
                doc_text = doc_text.replace("ë³¸ë¬¸:", "\n\në³¸ë¬¸:")  # âœ… "ë¬¸ì„œ:" ì•ì— ì¤„ë°”ê¿ˆ 2ê°œ ì¶”ê°€

            with st.expander(f"ë¬¸ì„œ {idx} | ì ìˆ˜: {score:.3f}"):
                st.write(doc_text)  # ë¬¸ì„œê°€ ê¸¸ ê²½ìš° ì¼ë¶€ë§Œ ì¶œë ¥

