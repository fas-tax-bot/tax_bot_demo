import os
import streamlit as st
import numpy as np
import faiss
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS
from dotenv import load_dotenv

# âœ… ìœ ì‚¬ë„ ì„ê³„ì¹˜ (ë‚´ì  ì ìˆ˜ê°€ 0 ì´ìƒì¸ ë¬¸ì„œë§Œ ì‚¬ìš©)
FINAL_VIEWABLE_DOCUMENT_SCORE = 0.1

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# OpenAI API ì„¤ì •
api_key = os.getenv("OPENAI_API_KEY")
os.environ["OPENAI_API_KEY"] = api_key
if not api_key:
    raise ValueError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")

# í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ
prompt_file_path = "src/prompt/prompt.txt"
def load_prompt_from_file(file_path):
    with open(file_path, "r", encoding="utf-8") as file:
        return file.read()
prompt_text = load_prompt_from_file(prompt_file_path)

# âœ… OpenAI ì„ë² ë”© ëª¨ë¸ ìƒì„±
embedding_model = OpenAIEmbeddings(model="text-embedding-3-small")

# âœ… ë²¡í„° ì •ê·œí™” í•¨ìˆ˜ ì¶”ê°€ (L2 ì •ê·œí™”í•˜ì—¬ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ë‚´ì ìœ¼ë¡œ ë³€í™˜)
def normalize(vectors):
    return vectors / np.linalg.norm(vectors, axis=1, keepdims=True)

# âœ… FAISS ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ (í•­ìƒ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ì‚¬ìš©í•˜ë„ë¡ ë³€ê²½)
vectorstore = FAISS.load_local(
    "vdb/faiss_index",
    embeddings=embedding_model,
    allow_dangerous_deserialization=True
)

# âœ… FAISS ì¸ë±ìŠ¤ ê°•ì œ ë³€í™˜ (METRIC_INNER_PRODUCT ì‚¬ìš©)
vectorstore.index.metric_type = faiss.METRIC_INNER_PRODUCT  # ë¬´ì¡°ê±´ ë‚´ì  ì‚¬ìš©

# âœ… MMR ê²€ìƒ‰ ì ìš©
retriever = vectorstore.as_retriever(
    search_type='mmr',
    search_kwargs={'k': 5, 'fetch_k': 10, 'lambda_mult': 0.9}
)

# âœ… RAG êµ¬ì„± ìš”ì†Œ ì„¤ì •
prompt = PromptTemplate(
    input_variables=["question", "context"],
    template=prompt_text
)
llm = ChatOpenAI(model_name="gpt-4o", temperature=0)
rag_chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)

# âœ… Streamlit ì•± ì„¤ì •
st.set_page_config(page_title="ì„¸ë¬´ì‚¬ ì±—ë´‡", page_icon="ğŸ¤–", layout="wide")

st.title("ğŸ“„ ì„¸ë¬´ì‚¬ ì±—ë´‡")
st.write("ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³  ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.")

# âœ… ì‚¬ìš©ì ì…ë ¥ í¼
with st.form("chat_form"):
    question = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:", placeholder="ì˜ˆ: ëŒ€í•™ì›ìƒì¸ ë°°ìš°ìê°€ 2024ë…„ 6ì›”ì— ì—°êµ¬ìš©ì—­ë¹„ë¡œ 500ë§Œì›ì„ ë°›ì€ ê²½ìš° ë°°ìš°ìê³µì œê°€ ê°€ëŠ¥í•´?")
    submit_button = st.form_submit_button(label="ì§ˆë¬¸í•˜ê¸°")

if submit_button and question:
    # âœ… FAISSë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œ ê²€ìƒ‰ (ìœ ì‚¬ë„ ì ìˆ˜ í¬í•¨)
    retrieved_documents_with_scores = vectorstore.similarity_search_with_score(
        question,
        search_type="mmr",
        search_kwargs={
            "k": 5,          # ìµœì¢… ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜
            "fetch_k": 10,   # MMR ê³„ì‚°ì— ì‚¬ìš©í•  í›„ë³´ ìˆ˜
            "lambda_mult": 0.9
        }
    )

    # ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì—†ì„ ê²½ìš° ì²˜ë¦¬
    if not retrieved_documents_with_scores:
        st.warning("ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        # âœ… RAGë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ìƒì„±
        with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
            response = rag_chain.invoke(question)

        # âœ… ë‹µë³€ ì¶œë ¥
        st.subheader("ğŸ’¡ ìƒì„±ëœ ë‹µë³€")
        st.write(response)

        # âœ… ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ë³€í™˜ (ë‚´ì  ê·¸ëŒ€ë¡œ ì‚¬ìš©)
        filtered_documents = [(doc, distance) for doc, distance in retrieved_documents_with_scores if distance >= FINAL_VIEWABLE_DOCUMENT_SCORE]

        # âœ… ì°¸ì¡°í•œ ë¬¸ì„œ ì¶œë ¥
        st.subheader("ğŸ” ì°¸ì¡°í•œ ë¬¸ì„œ")
        if not filtered_documents:
            st.info(f"ğŸ” ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. (ì¶œì²˜ ì—†ìŒ)")
        else:
            for idx, (doc, similarity) in enumerate(filtered_documents, 1):
                with st.expander(f"ë¬¸ì„œ {idx}: {doc.metadata.get('ì œëª©', 'ì œëª© ì—†ìŒ')} (ìœ ì‚¬ë„: {similarity:.3f})"):
                    st.write(f"**ë³¸ë¬¸:** {doc.metadata.get('ë³¸ë¬¸_ì›ë³¸', 'ì—†ìŒ')}")
                    st.write(f"**ì¶œì²˜:** {doc.metadata.get('source', 'ì¶œì²˜ ì—†ìŒ')}")
